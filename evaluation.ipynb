{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seelennebel\\dev\\llm\\llm-kernel\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from labels import id2label\n",
    "from transformers import DistilBertForTokenClassification, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seelennebel/AM_tokenizer\")    \n",
    "model = DistilBertForTokenClassification.from_pretrained(\"seelennebel/AM\")\n",
    "dataset = load_from_disk(\"./dataset\")\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending y_true with mbert_token_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "\n",
    "for true_classes in dataset[\"test\"][\"mbert_token_classes\"]:\n",
    "    y_true.append(true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for row in dataset[\"test\"]:\n",
    "    # converting tokens from mbert_tokens to ids\n",
    "    ids = tokenizer.convert_tokens_to_ids(row[\"mbert_tokens\"])\n",
    "    # creating attention mask for all ids\n",
    "    attention_mask = [1] * (len(ids) - 2)\n",
    "    # deleting special token ids\n",
    "    ids.pop(0)\n",
    "    ids.pop(-1)\n",
    "\n",
    "    inputs = {}\n",
    "    inputs[\"input_ids\"] = torch.tensor(ids).unsqueeze(0)\n",
    "    inputs[\"attention_mask\"] = torch.tensor(attention_mask).unsqueeze(0)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predicted_labels = torch.argmax(probabilities, dim=-1)\n",
    "    predicted_classes = []\n",
    "    for value in predicted_labels[0]:\n",
    "        predicted_classes.append(id2label[int(value)])\n",
    "\n",
    "    y_pred.append(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_flat = [label for seq in y_true for label in seq]\n",
    "y_pred_flat = [label for seq in y_pred for label in seq]\n",
    "labels = list(id2label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seelennebel\\dev\\llm\\llm-kernel\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "                 O       0.94      1.00      0.97    111356\n",
      "B-DRIVERLICENSENUM       0.88      0.07      0.13        99\n",
      "I-DRIVERLICENSENUM       0.86      0.71      0.78       756\n",
      "     B-DATEOFBIRTH       0.00      0.00      0.00       139\n",
      "     I-DATEOFBIRTH       1.00      0.11      0.20       595\n",
      "         B-ZIPCODE       1.00      0.01      0.01       145\n",
      "         I-ZIPCODE       0.92      0.65      0.77       452\n",
      "          B-TAXNUM       0.89      0.07      0.13       110\n",
      "          I-TAXNUM       0.97      0.14      0.24       497\n",
      "     B-BUILDINGNUM       0.00      0.00      0.00       155\n",
      "    B-TELEPHONENUM       0.93      0.66      0.77       193\n",
      "    I-TELEPHONENUM       0.84      0.94      0.88      1247\n",
      "         B-SURNAME       1.00      0.01      0.02       336\n",
      "         I-SURNAME       0.93      0.04      0.08       614\n",
      "           B-EMAIL       0.99      0.87      0.93       219\n",
      "           I-EMAIL       0.98      0.99      0.99      1972\n",
      "       B-SOCIALNUM       1.00      0.08      0.16       119\n",
      "       I-SOCIALNUM       0.84      0.48      0.61       548\n",
      "       B-GIVENNAME       0.00      0.00      0.00       427\n",
      "       I-GIVENNAME       0.70      0.01      0.02       612\n",
      "        B-PASSWORD       1.00      0.08      0.15       100\n",
      "        I-PASSWORD       0.89      0.88      0.89       665\n",
      "            B-CITY       1.00      0.00      0.01       297\n",
      "     I-BUILDINGNUM       0.00      0.00      0.00        51\n",
      "       B-IDCARDNUM       0.94      0.21      0.35       150\n",
      "       I-IDCARDNUM       0.94      0.41      0.57       848\n",
      "      B-ACCOUNTNUM       1.00      0.02      0.03       131\n",
      "      I-ACCOUNTNUM       0.98      0.14      0.24      1004\n",
      "        B-USERNAME       0.95      0.22      0.36       269\n",
      "        I-USERNAME       0.90      0.80      0.84      1309\n",
      "            I-CITY       0.87      0.70      0.78       596\n",
      "          B-STREET       0.93      0.10      0.19       136\n",
      "          I-STREET       0.86      0.77      0.81       313\n",
      "B-CREDITCARDNUMBER       0.00      0.00      0.00        61\n",
      "I-CREDITCARDNUMBER       1.00      0.05      0.10       487\n",
      "\n",
      "          accuracy                           0.94    127008\n",
      "         macro avg       0.80      0.32      0.37    127008\n",
      "      weighted avg       0.93      0.94      0.91    127008\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seelennebel\\dev\\llm\\llm-kernel\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\seelennebel\\dev\\llm\\llm-kernel\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true_flat, y_pred=y_pred_flat, labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9296\n",
      "Recall: 0.9358\n",
      "F1 Score: 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seelennebel\\dev\\llm\\llm-kernel\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true_flat, y_pred_flat, labels=labels, average=\"weighted\")\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
